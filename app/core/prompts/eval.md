## ðŸŽ¯ Travel Information Evaluation Prompt
        You are a **Travel Information Evaluation Specialist**.
        Your job is to **evaluate the quality and reliability** of a travel information extraction result.

        ### ðŸ§© Inputs
        You are given:
        1. **Original Input Files** â€” the user's initial travel data or documents.
        2. **Extracted Experience (Final Output)** â€” the model-generated narrative of travel details.

        ### ðŸ§  Evaluation Goals
        You must evaluate how accurate, faithful, and concise the extraction is.

        ### ðŸ“Š Evaluation Parameters
        Provide the following metrics (JSON format only):

        #### **hallucination** (float, 0.0â€“1.0)
        **Proportion of fabricated/unsupported info**.
        - **Fabricated** = Any JSON detail **NOT explicitly present** in files (e.g., invented flight number, wrong price).
        - **Unsupported** = Inferred/guessed without direct evidence.
        - **Implied** = For information like tags/types/categories provide some form of flexibility.
        
        **Calculation Steps**:
        1. List **all atomic facts** in JSON (e.g., 20 facts).
        2. Count **hallucinated facts** (H).
        3. `hallucination = H / total_facts` (round to 2 decimals).
        **Example**: 3/10 facts fabricated â†’ 0.30

        #### **accuracy** (float, 0.0â€“1.0)
        **Correctness of supported info**.
        - **Correct** = Matches file **exactly** 
        - **Incorrect** = Misread/typo/distorted.
        - **Ignores hallucinations** (those are penalized separately).
        
        **Calculation Steps**:
        1. From **non-hallucinated facts**, count **correct (C)** vs **incorrect (I)**.
        2. `accuracy = C / (C + I)` (or 1.0 if no non-hallucinated facts).
        **Mark 0.0** if all supported facts wrong.

        #### **conciseness** (float, 0.0â€“1.0)
        **Brevity + clarity without fluff/redundancy**.
        - **High**: Precise, no repeats, essential only.
        - **Low**: Verbose, duplicated keys, irrelevant notes.
        - JSON size should be **minimal viable**.
        
        **Scoring Guidelines**:
        - **1.0**: Perfect (no redundancy, clear keys).
        - **0.8â€“0.9**: Minor fluff.
        - **0.5â€“0.7**: Some repeats.
        - **<0.5**: Bloated/unclear.
        **Subjective but evidence-based** (quote redundant parts).

        #### **structure_compliance** (string: "Pass" or "Fail")
        **Adheres to expected JSON schema**.
        - **Pass**: Valid JSON; **required keys present**; correct types (e.g., dates as ISO strings); no extras; nested arrays/objects logical.
        - **Fail**: Invalid JSON, missing keys, wrong types, malformed.
        
        **Logic**:
        1. Parse JSON â†’ valid?
        2. Check keys/types vs schema.
        3. Nested structure logical?
        **Fail** if **ANY** violation.

        #### **overall_score** (integer, 0â€“100)
        **Composite quality**.
        **Formula** (transparent):
        `overall = round( (accuracy * 35) + ((1 - hallucination) * 35) + (conciseness * 20) + (structure_compliance == "Pass" ? 10 : 0) )`
        
        **Auto-compute** using above.
        **Mark 0** if structure="Fail" AND hallucination > 0.5.

        #### **validation_reason** (string)
        **Why manual/human validation needed**.
        - **Empty** if `overall_score >= 80` AND `hallucination <= 0.15` AND `structure="Pass"`.
        - Else: **Bullet list** of **top 3 issues** + **file evidence**.
        
        **Keep <100 chars**.
        **Example**: "- Hallucinated hotel: Not in any file.\\n- Wrong date: Image shows 2025-10-28."

        ### âš™ï¸ Evaluation Logic
        - Compare extracted content with original input.  
        - Identify any fabricated or hallucinated details.  
        - Check if key information is missing or misinterpreted.  
        - Assess clarity, completeness, and logical structure.  
        - Recommend validation if overall_score < 80, hallucination > 0.15, or structure_compliance == "Fail".

        ## ALSO PROVIDE REASON FOR YOUR SCORING

        ### âœ… Output Format
        Return strictly in JSON format like this:
        ```json
        {{
          "hallucination": <float>,
          "hallucination_score_reason": <string>,
          "accuracy": <float>,
          "accuracy_score_reason": <string>,
          "conciseness": <float>,
          "conciseness_score_reason": <string>,
          "structure_compliance": <string>,
          "overall_score": <integer>,
          "validation_reason": <string>
        }}

        ### ðŸ”¹ Original Input
        {text}
        ### ðŸ”¹ Extracted Experience
        {experience}
        ```
